---
title: 'Tipolog√≠a y ciclo de vida de los datos: PRA2'
author: "Autor: Iv√°n L√≥pez-Baltasar Benito | David Quiles G√≥mez"
date: "Junio 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducci√≥n
******
## Presentaci√≥n

En esta actividad se elabora un caso practico, consistente en el tratamiento de un conjunto de datos (en ingles, dataset), orientado a aprender a identificar los datos relevantes para un proyecto analitico y usar las herramientas de integracion, limpieza, validacion y analisis de las mismas.


## Objetivos

Aprender a aplicar los conocimientos adquiridos y su capacidad de resolucion de problemas en entornos nuevos o poco conocidos dentro de contextos mas amplios o multidisciplinares.
Saber identificar los datos relevantes y los tratamientos necesarios (integraci√≥n, limpieza y validaci√≥n) para llevar a cabo un proyecto anal√≠tico.
Aprender a analizar los datos adecuadamente para abordar la informaci√≥n contenida en los datos.
Identificar la mejor representaci√≥n de los resultados para aportar conclusiones sobre el problema planteado en el proceso anal√≠tico.
Actuar con los principios √©ticos y legales relacionados con la manipulaci√≥n de datos en funci√≥n del √°mbito de aplicaci√≥n.
Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendr√° que ser en gran medida autodirigido o aut√≥nomo.
Desarrollar la capacidad de b√∫squeda, gesti√≥n y uso de informaci√≥n y recursos en el √°mbito de la ciencia de datos.
 
## Competencias
* Capacidad de analizar un problema en el nivel de abstracci√≥n adecuado a cada situaci√≥n y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las t√©cnicas espec√≠ficas de tratamiento de datos (integraci√≥n, transformaci√≥n, limpieza y validaci√≥n) para su posterior an√°lisis  

## Descripcion del dataset 
En esta practica  vamos a trabajar con el juego de datos https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/ el cual contiene dos datasets, uno de vinos blancos y otro de vinos tintos. 

Tenemos dos datasets, uno correspondiente a analisis de vinos blancos y el otro de vinos tintos. 
Ambos datasets contienen los siguientes originales 11 atributos de entrada:

  fixed acidity
  volatile acidity
  citric acid
  residual sugar
  chlorides
  free sulfur  dioxide
  total sulfur  dioxide	
  density	
  pH	
  sulphates	
  alcohol


correspondientes a pruebas fisioquimicas, y uno de salida: "quality". 

## Importancia y objetivos del Dataset

A partir de los dos conjuntos de datos, plantearemos varias soluciones para determinar cuales son y en que medida afectan a la calidad del vino. 

Obviamente el estudio ser· intersante para toda aquella persona relacionada con la industria vinicola y con todas aquellas personas que sientan interes por la composicion fisio-quimica de los vinos y como afecta a su calidad. 



## Nota: Propiedad intelectual 

Uso de paquete mclust:
  Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5:
  clustering, classification and density estimation using Gaussian finite
  mixture models The R Journal 8/1, pp. 205-233
  

******
# Carga y limpieza del dataset
******

Cargamos los paquetes R que vamos a usar
```{r message= FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(arules)
library(Matrix)
```

```{r message= FALSE, warning=FALSE}
blanco<-read.csv("vinos/winequality-white.csv", header=T, sep=";")
tinto<-read.csv("vinos/winequality-red.csv", header=T, sep=";")

```

Vamos a a√±adirle la clase a cada juego de datos para despues unir ambos datasets.
```{r message= FALSE, warning=FALSE}
blanco$tipo<-'B'
tinto$tipo<-'T'

nomCols <- c("acidez_fija", "acidez_volatil", "acido_citrico", "azucar_residual", "cloruros","diox_azufre_libre","diox_azufre_total","densidad","pH","sulfatos", "alcohol","calidad", "tipo")

colnames(blanco) <- nomCols
colnames(tinto) <- nomCols

#str(blanco)
summary(blanco)
#str(tinto)
summary(tinto)
```

Ahora unimos ambos datasets
```{r message= FALSE, warning=FALSE}
# Unimos los dos juetos de datos en uno solo
totalData <- bind_rows(blanco,tinto)
filas=dim(totalData)[1]

# Factorizamos la variable tipo
totalData$tipo <- as.factor(totalData$tipo)

str(totalData)
summary(totalData)
```

## Nulos y/o elementos vac√≠os
Comprobamos que no haya valores vac√≠os o nulos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estad√≠ssticas de valores vacios
colSums(is.na(totalData))
colSums(totalData=="")
```

Una vez comprobado que no hay valores nulos ni vacios y que podremos aprovechar toda la informacionfderrrrrr5, comprobamos la valores extremos 

## Valores extremos

En el resumen descriptivo pudimos observar tanto en el grupo vinos tintos como en el de blancos, los valores m√°ximos de dioxido de azufre total parecen muy distantes de sus medidas de tencencia central. Vamos a identificarlos de manera gr√°fica con un diagrama box plot.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# comprobamos outliers en dioxido de azufre total en los blancos
#ggplot(totalData, aes(x=tipo, y=diox_azufre_total)) +  geom_point(size=2, shape=23)
datos.bp <-boxplot(blanco$diox_azufre_total, main="Blancos - Dioxido azufre total", horizontal = T)
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
# comprobamos outliers en dioxido de azufre total en los tintos
datos.bp <-boxplot(tinto$diox_azufre_total, main="Tintos - Dioxido azufre total", horizontal = T)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
boxplot.stats(blanco$diox_azufre_total)$out
boxplot.stats(tinto$diox_azufre_total)$out
```

Vemos que el sistema detecta 20 valores at√≠picos en los vinos blancos y 56 en los tintos. No tenemos un conocimiento suficiente para valorar si se han producido por errores o por diferentes metodolog√≠as de medici√≥n o si por el contrario, son valores correctos por lo que vamos solamente vamos a sacar de la muestra los que est√°n m√°s alejados del rango intercuart√≠lico. 

De la muestra total sacamos el que tiene un valor > 400 y es blanco y de la de tintos los dos que tienen un valor superior a 250.

```{r echo=TRUE, message=FALSE, warning=FALSE}
blanco <-subset(blanco, diox_azufre_total<400)
tinto <- subset(tinto, diox_azufre_total<250)
totalData <- bind_rows(blanco,tinto)
filas=dim(totalData)[1]
# Factorizamos la variable tipo
totalData$tipo <- as.factor(totalData$tipo)


#‚ò∫totalData <- subset(totalData, (tipo=="B"& diox_azufre_total < 400) | (tipo == "T" & diox_azufre_total < 250))
ggplot(totalData, aes(x=tipo, y=diox_azufre_total)) +  geom_point(size=2, shape=23)
```


# An√°lisis de los datos

```{r echo=TRUE, message=FALSE, warning=FALSE}

# mostramos un histograma de la calidad
ggplot(data = totalData[1:filas,],aes(x=calidad))+geom_histogram()+ geom_density(alpha=.2, fill="#FF6666") 

# Relacion entre calidad y tipo de vino
ggplot(data=totalData[1:filas,],aes(x=calidad,fill=tipo))+geom_bar()

# Grafico de frecuencias
ggplot(data = totalData[1:filas,],aes(x=calidad,fill=tipo))+geom_bar(position="fill")+ylab("Frecuencia")
```

Se puede deducir de los gr√°ficos que los vinos blancos de la muestra tienen m√°s calidad que los tintos.  



## An√°lisis de la normalidad y homogeneidad de la varianza


Vamos a comprobar la normalidad de la calidad en ambos grupos de vinos. Utilizaremos los tests de **Kolmogorov-Smirnov** y **Shapiro-Wilk**

```{r message= FALSE, warning=FALSE}
##
ks.test(tinto$calidad, pnorm, mean(tinto$calidad), sd(tinto$calidad))
shapiro.test(tinto$calidad)

ks.test(blanco$calidad, pnorm, mean(blanco$calidad), sd(blanco$calidad))
shapiro.test(blanco$calidad)

```
En ambos test se rechaza la hip√≥tesis nula, por tanto consideramos que la calidad no se distribuye mediante una distribuci√≥n normal en ninguno de los dos grupos. No obstante, por el **teorema central del l√≠mite** se podr√≠a considerar que los datos siguen una distribuci√≥n normal.


Analizaremos la homocedasticidad de la varianza mediante el **test de Flinger-Killen** en cuanto a los grupos conformados por los vinos tintos y los blancos.  

```{r message= FALSE, warning=FALSE}
##
b <- blanco$calidad
t <- tinto$calidad
fligner.test(calidad ~ tipo, data= totalData)
```
Dado que el p-valor es > 0.05 podemos aceptar la hip√≥stesis nula de que las varianzas de ambas muestras son homog√©neas.


Aplicaremos la prueba **t de Student** para comprobar si tenemos diferencias estad√≠sticamente significativas en la media de la calidad de ambos grupos de vinos.


```{r message= FALSE, warning=FALSE}
## Realizamos el test por tipo de vino
t.test(calidad ~ tipo, data = totalData)

```
Dado que el p-valor es inferior al nivel de significancia, debemos rechazar la hip√≥tesis nula, considerando que las medias de ambos grupos son distintas.


# M√©todos supervisados - √Årboles de decisi√≥n
## C4.5
Vamos a construir un arbol de decisi√≥n mediante el algoritmo **C4.5** utilizando la biblioteca RWeka. 
Comenzamos dividiendo la muestra en un dataset de entrenamiento y otro de prueba con una proporci√≥n de 70-30 sobre el total.  

```{r message= FALSE, warning=FALSE}

library(RWeka)
library(caret)

#con sample_frac obtenemos una muestra simple del 70% del dataset
vino_entrenamiento <- sample_frac(totalData, .7)
vino_prueba <- setdiff(totalData, vino_entrenamiento)
summary(vino_entrenamiento$tipo)

```

En RWeka el algoritmo C4.5 se llama J48. Como se requiere que el atributo sea categ√≥rico, vamos a clasificar los vinos por tipo (Blanco o Tinto).  

```{r message= FALSE, warning=FALSE}

# fit model
resultJ48 <- J48(tipo~., vino_entrenamiento) 
# Resumen del modelo
summary(resultJ48)

# predicciones
predicciones <- predict(resultJ48, newdata = vino_prueba)

# precision del modelo
table(vino_prueba$tipo, predicciones)

```

Vemos que el resultado es excelente, el modelo nos clasifica los vinos con una precisi√≥n del 99.6% con un √≠ndice **kappa=0.99*   que nos indica que nuestra clasificaci√≥n es un 98,79% mejor que una clasificaci√≥n aleatoria.  

Ahora vamos a clasificar los vinos en funcion de su calidad. Como el m√©todo que estamos usando requiere que la variable de clase sea categ√≥rica, factorizamos el atributo "calidad".

```{r message= FALSE, warning=FALSE}

# fit model
resultJ48 <- J48(as.factor(calidad)~., vino_entrenamiento) 
# Resumen del modelo
summary(resultJ48)
```

Comprobamos que el modelo se ajusta peor, con una precisi√≥n del 88.34% y un √≠ndice kappa=82,47%.

Vamos a comprobarlo con el set de prueba.

```{r message= FALSE, warning=FALSE}
# predicciones
predicciones <- predict(resultJ48, newdata = vino_prueba)
predicciones <- as.list.data.frame(predicciones)
#analisis de las prediciones
summary(predicciones)
#analisis de los datos reales
summary(vino_prueba$calidad)
# precision del modelo. 
table(vino_prueba$calidad, predicciones)

# calculamos la media de los cuadrados de las desviaciones 
dm <- function(actual, predicted){
  mean((actual - predicted)^2)
}

error_C45 = dm(vino_prueba$calidad, predicciones)
error_C45
```

Comprobamos que en este caso, los resultados son peores.  

## CART
Ahora vamos a utilizar  un arbol de decisi√≥n para regresi√≥n y clasificaci√≥n (**CART**) para predecir la calidad del vino en funci√≥n de sus caracter√≠sticas.  

```{r message= FALSE, warning=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)

```


```{r message= FALSE, warning=FALSE}
arbol_2 <- rpart(calidad ~ ., data = vino_entrenamiento,method  = "anova")
arbol_2
rpart.plot(arbol_2)
```

Se observa que para construir el √°rbol solo tiene en cuenta las variables alcohol y acidez vol√°til.

```{r message= FALSE, warning=FALSE}
plotcp(arbol_2)
printcp(arbol_2)
```

Realizamos una poda  

```{r message= FALSE, warning=FALSE}
arbol_2 <- prune(arbol_2, cp = 0.011000)
rpart.plot(arbol_2)
```


Vamos a evaluar el modelo contra los datos de prueba.  

```{r message= FALSE, warning=FALSE}
# Evaluacion del modelo
prediccion_2 <- predict(arbol_2, newdata = vino_prueba,type = "vector")


#resumen de la predicci√≥n
summary(prediccion_2)
#resumen de los datos reales
summary( vino_prueba$calidad )

#table(vino_prueba$calidad, prediccion_2)

#Podemos medir la calidad del modelo con la desviacion media
errorCART = dm(vino_prueba$calidad, prediccion_2)
errorCART

cat("Error en la estimaci√≥n del atributo calidad (C4.5, CART ): ", c(error_C45, errorCART))

```

Vemos que se comporta mucho mejor el m√©todo CART para estimar la calidad, que el metodo C4.5. En principio tiene sentido ya que el segundo realmente est√° clasificando las observaciones en un atributo factorizado.

# M√©todos no supervisados - An√°lisis de agregaci√≥n.  
## K-means
Vamos a realizar un an√°lisis de agregaci√≥n. Cargamos  los datos y nos quedamos unicamente con las 11 columnas que contienen los test fisioqu√≠micos
```{r message= FALSE, warning=FALSE}
x <- totalData[,1:11]

```

```{r echo=TRUE, message=FALSE, warning=FALSE}
#
#x_n <- as.data.frame(lapply(x[1:11], normalize))
#comprobar la normalizacion con la variable alcohol
summary(x)
```

Aunque el n√∫mero de clusters deber√≠a ser 2, vamos a comprobar los resultados con varios valores.  

```{r message= FALSE, warning=FALSE}
library(cluster)


d <- daisy(x) 
resultados <- rep(0, 4)
for (i in c(2,3,4))
{
  fit           <- kmeans(x, i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}
```


Mostramos en un gr√°fica los valores de las siluetas media de cada prueba para comprobar que n√∫mero de clusters es el mejor.
```{r message= FALSE, warning=FALSE}
plot(2:4,resultados[2:4],type="o",col="blue",pch=0,xlab="N√∫mero de clusters",ylab="Silueta")

```

Ahora vamos a utilizar el m√©todo que ofrece la menor suma de los cuadrados de las distancias de los puntos de cada grupo con respecto a su centro (withinss), con la mayor separacion entre centros de grupos (betweenss)  
```{r message= FALSE, warning=FALSE}
resultados <- rep(0, 4)
for (i in c(2,3,4))
{
  fit           <- kmeans(x, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:4,resultados[2:4],type="o",col="blue",pch=0,xlab="N√∫mero de clusters",ylab="tot.tot.withinss")
```


Con ambos m√©todos el mejor resultado se obtiene con k=2 tal y como era de esperar.

Vamos a aplicar el algoritmo **K-means** con k=2  

```{r message= FALSE, warning=FALSE}
fit2       <- kmeans(x, 2,nstart = 50,iter.max = 15)
y_cluster2 <- fit2$cluster
```


De la siguiente forma podemos visualizar para cada grupo de vinos, para que tipo ha sido clasificado y para cual deberia haber sido clasificado.

```{r message= FALSE, warning=FALSE}
plot( totalData[c(8,11)],col=fit2$cluster)

plot( totalData[c(8,11)],col=totalData$tipo)

plot( totalData[c(8,9)],col=fit2$cluster)
plot( totalData[c(8,9)],col=totalData$tipo)

plot( totalData[c(1,7)],col=fit2$cluster)
plot( totalData[c(1,7)],col=totalData$tipo)
```

Comprobamos que la acidez fija y el dioxido de azufre total son buenos indicadores para diferenciar el tipo de vino, esto ya lo hab√≠amos visto con el arbol de decisi√≥n del an√°lisis previo*. Comprobamos que los cloruros y el dioxido de azufre total deben tambi√©n ser buenos indicadores.

* Var√≠a de una ejecucion a otra!

```{r message= FALSE, warning=FALSE}

plot( totalData[c(5,7)],col=fit2$cluster)
```

Evaluaci√≥n del modelo  

```{r message= FALSE, warning=FALSE}
table(fit2$cluster,totalData$tipo)
```

Obtenemos el porcentaje de precisi√≥n del modelo
```{r message= FALSE, warning=FALSE}
100*(3622+1513)/(6494)
```
De lo que se obtiene una precisi√≥n del 79.07, que es aceptable aunque inferior a la obtenida con el arbol de decisi√≥n CART.



#Regresion lineal

Partiendo del dataset de vinos blancos, vamos a hacer un an√°lisis de regresi√≥n para estimar la calidad del vino.
```{r message= FALSE, warning=FALSE}
blancoQ <- blanco[,1:12]
str(blancoQ)
```
Vamos a dividir las observaciones en dos grupos, uno de entrenamiento para ajustar el modelo (70% de los datos) y uno de test (30% de los datos)  

```{r message= FALSE, warning=FALSE}
training <- sample_frac(blancoQ, .7)
test <- setdiff(blancoQ, training)

modelo <- lm(calidad ~ ., data = training)
summary(modelo)
```

Vemos que el valor R2 ajustado es bajo, 0.2977 por lo que el modelo no es capaz de predecir con precisi√≥n la calidad.
Vamos a verificar

```{r message= FALSE, warning=FALSE}
# MSE empleando las observaciones de entrenamiento
training_mse <- dm(modelo$fitted.values, training$calidad)
training_mse

# MSE empleando nuevas observaciones
predicciones <- predict(modelo, newdata = test)
test_mse <- dm(predicciones, test$calidad)
test_mse

```

Vamos a generar otro modelo para predecir el nivel de alcohol. Quitamos el atributo calidad ya que no es un atributo fisioqu√≠mico del vino.  

```{r message= FALSE, warning=FALSE}
blancoA <- blanco[,1:11]
str(blancoA)

training <- sample_frac(blancoA, .7)
test <- setdiff(blancoA, training)

modelo <- lm(alcohol ~ ., data = training)
summary(modelo)
```

En este caso, el valor R2 ajustado es alto, 0.8579 por lo que el modelo en este caso s√≠ es capaz de predecir con exactitud el nivel de alcohol del vino.

Comprobamos c√≥mo de bueno es el modelo prediciendo nuevas observaciones que no han participado en ajuste. La estimaci√≥n del error de predicci√≥n se obtiene mediante el Mean Square Error (MSE).

```{r message= FALSE, warning=FALSE}
# MSE empleando las observaciones de entrenamiento
training_mse <- dm(modelo$fitted.values, training$alcohol)
training_mse

# MSE empleando nuevas observaciones
predicciones <- predict(modelo, newdata = test)
test_mse <- dm(predicciones, test$alcohol)
test_mse
```

Se puede observar que el modelo tiene un MSE muy bajo tanto en las predicciones con las observaciones de entrenamiento como las nuevas observaciones, incluso m√°s bajo en las segundas por lo que podr√≠amos decir que el modelo es √∫til para predecir la graduaci√≥n de alcohol de un vino.

